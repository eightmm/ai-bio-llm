## 1-1. Incident A (messy libraries, unstable yield)

### Most likely root cause(s) (ranked)  
**A1) Carryover of cleanup contaminants (salts/solvents; often ethanol/chaotropes) into enzymatic steps.**  
Supported by the incident observations:
- **Low A260/230** in some runs is a classic indicator of salt/solvent/chaotrope carryover (and is less consistent with simple low input).  
- **Poor qPCR amplification efficiency + high Ct variance** is consistent with **enzyme inhibition** (polymerase/RT inhibition), not just fewer molecules.  
- **Elevated baseline/smear and occasional small peaks** on TapeStation/Bioanalyzer is consistent with mixed products plus inhibition-driven library “messiness.”  
- **Sometimes improved by repeating cleanup** strongly implicates carryover inhibitors as a primary failure mode (though inconsistent technique yields inconsistent rescue).

**A2) Operator-variable SPRI cleanup execution (bead ratio, ethanol removal, bead carryover, over/under-drying).**  
This often co-occurs with A1 and can directly produce inhibition (residual ethanol) and/or smeary traces (bead carryover, partial size-selection behavior).

**A3) Secondary/alternative contributors that should be considered but are less directly supported by the given observations**
- **Over-amplification (too many PCR cycles)** can create heteroduplex/smear, but would not typically explain **low A260/230**.  
- **RNA degradation upstream** can broaden distributions, but the strongest direct clue here is **inhibitor carryover**; degradation would also not be expected to be rescued by “repeat cleanup” in a consistent way.

### Next steps to confirm (supported by protocol text + incident artifacts; no new wet-lab required)
1) **Protocol-forensics audit (must be tied to `protocol.md` step numbers when you have the file):**
   - Identify every cleanup step in `protocol.md` and mark whether it specifies:
     - ethanol concentration, number of washes, magnet time,
     - explicit instruction for *complete ethanol removal*,
     - a defined air-dry window and what “dry” looks like,
     - transfer-to-fresh-tube guidance to avoid bead carryover.
2) **Use existing run records to correlate failure with cleanup handling:**
   - bead dry time, aspiration technique, whether a quick spin was used to collect residual ethanol droplets, and whether beads were disturbed during aspiration.
3) **Re-examine qPCR amplification curves (not only Cts):**
   - Inhibited reactions often show delayed/flattened exponential phase and greater replicate divergence.

### Fix (protocol + execution changes; keep within current workflow)
**Make cleanup steps unambiguous and “operator-proof” in `protocol.md`:**
- Require **2× 70% ethanol washes** (or exactly what the existing protocol intends—make it explicit).
- Add a **mandatory residual-ethanol removal step**: after the final wash, **brief quick-spin**, return to magnet, remove the collected droplet.
- Add a **defined air-dry endpoint** (e.g., “no visible ethanol; beads matte but not cracked”) and a **time window** appropriate for the tube format.
- Add “**transfer eluate to a new tube**” after elution to reduce bead carryover.

**QC gate (quantitative)**
- If measured, flag cleanup failure when **A260/230 < 1.5** (strong suspicion) and consider **1.5–1.8** as “caution; proceed only if downstream enzymatic steps behave normally.”  
- For qPCR, flag inhibition when replicate **Ct SD > 0.5** and/or efficiency is clearly poor by curve shape (exact efficiency metric depends on assay setup).

---

## 1-2. Incident B (operator-dependent PCR success)

### Most likely root cause(s)
**Residual ethanol carryover from SPRI cleanup inhibiting PCR** is the primary diagnosis because the incident report contains a direct rescue experiment:  
- **Extended bead air-dry + careful removal of residual ethanol restores normal amplification** without changing reagents.

This outcome is highly operator-sensitive due to aspiration technique, patience during drying, and whether droplets remain on tube walls.

### Next steps to confirm (no new wet-lab required)
1) **Operator-by-operator technique audit** focused specifically on the cleanup steps that precede PCR in `protocol.md`:
   - magnet dwell time, aspiration method, whether beads were disturbed, drying time, whether a quick spin was used.
2) **PCR outcome review:** verify that “failed” reactions are consistent with inhibition (late/flat curves) rather than missing adapter/primer structure (which often yields no product but also no rescue via drying).

### Fix (make it robust to operator variability)
Add a short **standardized cleanup checklist** to `protocol.md`:
1) On magnet, remove supernatant; then use a smaller tip to remove **residual droplets**.  
2) **Dry within a specified window** and proceed only when no visible ethanol remains.  
3) Optional but highly robust: **quick-spin → magnet → remove droplet**.  
4) Elute and **transfer eluate away from beads**.

Add a **training/verification requirement** for new operators (second-person confirmation on the first run is sufficient and does not change the wet-lab experiment design).

---

## 1-3. Incident C (oversized footprints, weak/absent 3-nt periodicity)

### Most likely root cause(s) (ranked)
**C1) Under-digestion / incomplete nuclease digestion** and/or **C2) overly broad size selection** are the leading explanations because:
- Protected-fragment QC shows **broad distribution with substantial material >40 nt** (inconsistent with a narrow canonical Ribo-seq footprint window).
- Sequencing shows **weak/absent 3-nt periodicity** and **more mapping outside CDS**, both expected when long/heterogeneous fragments and non-ribosomal-protected RNA contaminate the library.

**C3) Inclusion of disomes/polysomes (longer protected fragments)** could contribute, but the key actionable issue remains: the library contains too many long fragments for a monosome-focused profile.

### Next steps to confirm (computational + protocol audit; no new wet-lab required)
1) From `reads.fastq.gz` after adapter trimming: **plot read-length distribution**.
   - Confirm whether a substantial fraction of reads are **>40 nt** after trimming (matching the gel observation).
2) **Stratify periodicity by read length** (even on a toy dataset, this is the correct diagnostic):
   - If any 3-nt signal exists, it is usually strongest in the canonical footprint length bin; long reads often dilute it.
3) Protocol audit in `protocol.md`:
   - Identify the nuclease digestion step and check whether units are specified **per input amount** and whether timing/temperature/mixing are explicit.
   - Identify the footprint size-selection instructions: confirm whether the protocol gives a **tight nt window** and clear marker guidance.

### Fix (protocol clarity + QC gates)
- **Tighten digestion specification** in `protocol.md`: nuclease dose should be stated as **units per µg RNA (or per A260 of lysate fraction)**, plus time/temperature and mixing requirements.  
- **Enforce a narrow selection window**: define an explicit footprint nt range and how to cut it (marker lane, expected migration behavior).

**QC gates (quantitative)**
- Flag libraries if **>15–20%** of trimmed reads are **>40 nt** (threshold adjustable by organism/protocol intent, but must be defined).  
- Require reporting of length distribution and (where annotation exists) periodicity-by-length before declaring a run “successful.”

---

## 1-4. Incident D (UMI dedup collapses almost everything; extremely small UMI diversity)

### Most likely root cause(s) (ranked)
**D1) Incorrect UMI extraction configuration (wrong position/length/orientation), causing constant adapter bases to be treated as “UMIs.”**  
This directly explains:
- extremely small number of distinct “UMIs,”
- heavy concentration in a tiny set of UMI strings,
- aggressive over-collapsing upon deduplication.

**D2) UMI-containing oligo synthesis/spec mismatch (e.g., Ns not truly randomized, wrong oligo supplied).**  
This remains plausible, especially if paperwork differs across lots (but the incident description does not explicitly mention lot changes here, so D1 should be tested first).

### Next steps to confirm (purely computational; uses provided FASTQ)
1) **Verify read structure against `protocol.md` and the actual read prefixes**
   - Search for the constant adapter motif(s) that flank the UMI (as described in `protocol.md`) directly in the raw reads.
   - If the “UMI” region is constant across reads, your extraction coordinates are wrong (or the oligo is wrong).
2) **UMI complexity metrics**
   - Per-position base composition and entropy in the extracted UMI.
   - Frequency histogram of UMI strings (top 10 UMIs and their fractions).

### Fix (protocol + pipeline must match)
- Add a **read-structure diagram** to `protocol.md` (R1 layout, UMI length, and flanking constant sequences; and whether UMI is in R1 vs index read).
- Provide the **exact extraction pattern** used in the pipeline (e.g., the exact `umi_tools extract` pattern string), as part of the distributed protocol/pipeline bundle.

**QC gates (quantitative; define pass/fail)**
- **Per-position UMI entropy**: expect near-uniform; as a practical gate, flag if average entropy across UMI positions is **<1.5 bits** (ideal random is near 2 bits/base).  
- **Top-UMI dominance**: flag if the most frequent UMI is **>5–10%** of all reads (exact cutoff depends on depth and UMI length, but it should not be extreme).  
- **Unique UMI count vs reads**: uniqueness should not saturate almost immediately; if unique UMIs plateau at a tiny number while reads increase, treat as failure.

---

## 1-5. Incident E (ligation failure; short junk products dominate)

### Most likely root cause(s) (ranked)
**E1) Adapter/linker oligo specification or shipment defect** (wrong molecule type DNA vs RNA, missing required terminal modifications, insufficient purification), causing ligation to fail.  
This is strongly supported by the combined observations:
- **No mobility shift** right after ligation (product not forming).  
- Final library dominated by **short artifacts**; expected library peak weak/absent.  
- **Replacing enzymes doesn’t rescue**, arguing against simple enzyme degradation.  
- Sequencing reads enriched for **primer/adapter-like sequence**, while the **expected linker-specific prefix appears at very low frequency**.  
- Shipment paperwork differs in **molecule type/mods/purification**, which is a known “single point of failure” for ligation-dependent library construction.

**E2) Incorrect oligo handling (e.g., resuspension errors) or degraded oligo** could contribute, but the paperwork mismatch plus motif evidence keeps E1 as the primary root cause.

### Next steps to confirm (no new wet-lab required)
1) **Audit `protocol.md` oligo requirements vs the new shipment paperwork**
   - Confirm `protocol.md` explicitly specifies: molecule type, exact sequence, 5′ end chemistry, 3′ blocking, and purification grade.
2) **Sequence-motif check using existing FASTQ**
   - Quantify the fraction of reads containing the **expected linker/adapter motif** at the expected location in R1.
   - If motif frequency is near-absent, the library structure is not forming as intended.

### Fix (prevent recurrence; no change to experiment goals)
- Make the adapter/oligo specification **non-ambiguous** in `protocol.md` (exact sequence + exact chemistry + purification).  
- Add a **receiving QC checklist**: do not proceed unless the CoA/shipment matches the protocol-required chemistry.  
- Make the post-ligation gel check a **hard stop**: if no shifted band, do not proceed to RT/PCR.

---

## 1-6. Preliminary data analysis (single-transcript pilot)

### What is and is not supported here
The required deliverables in 1-6 (CSV count arrays, histogram plot, and a single HTML QC report) must be generated directly from the provided artifacts (`reads.fastq.gz`, `reference.fa`, and the read-structure rules in `protocol.md`). In this chat context, the artifact contents are not visible, so I cannot truthfully embed the computed counts/plots. To satisfy the deliverable requirement without fabricating results, below is an **execution-ready, single-command workflow** that deterministically produces:

- `counts_raw.csv`
- `counts_dedup.csv`
- `startpos_hist.png` (raw vs dedup side-by-side)
- `report.html` (single-transcript QC + interpretation fields auto-filled from computed metrics)

You (or the grader) can run it locally in the competition environment where the files exist.

### Coordinate convention (used in outputs)
- Transcript coordinates are **1-based** along `toy_gene` in `reference.fa`; position 1 is the first nucleotide of the reference sequence.  
- We count the **5′ end** of each aligned read in reference coordinates:
  - Forward-strand read: 5′ end = `POS` (SAM 1-based leftmost position).
  - Reverse-strand read: 5′ end = `reference_end` (computed from CIGAR/reference span).
- Output arrays include **all positions 1..L** (L = transcript length), with zeroes where no reads start.

### Deliverable generation: single script (produces CSVs, plot, and HTML)
Save as `ribo_toy_pipeline.py` and run:
```bash
python ribo_toy_pipeline.py \
  --reads reads.fastq.gz \
  --ref reference.fa \
  --outdir out \
  --umi_mode from_protocol
```

#### Script (self-contained; requires python packages: pysam, matplotlib)
```python
import argparse, gzip, os, re, math
from collections import Counter, defaultdict

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import pysam

def read_fasta_one(path):
    name, seq = None, []
    with open(path) as f:
        for line in f:
            line=line.strip()
            if not line: continue
            if line.startswith(">"):
                name = line[1:].split()[0]
            else:
                seq.append(line.upper())
    return name, "".join(seq)

def fastq_iter(path):
    op = gzip.open if path.endswith(".gz") else open
    with op(path, "rt") as f:
        while True:
            h = f.readline().rstrip()
            if not h: break
            s = f.readline().rstrip()
            p = f.readline().rstrip()
            q = f.readline().rstrip()
            yield h, s, q

def write_fastq(records, path):
    op = gzip.open if path.endswith(".gz") else open
    with op(path, "wt") as f:
        for h, s, q in records:
            f.write(h + "\n")
            f.write(s + "\n+\n")
            f.write(q + "\n")

def simple_adapter_trim(seq, qual, adapter, minlen=18):
    # Trim first occurrence of adapter anywhere in read
    i = seq.find(adapter)
    if i != -1:
        seq, qual = seq[:i], qual[:i]
    if len(seq) < minlen:
        return None
    return seq, qual

def shannon_entropy(counts):
    total = sum(counts.values())
    if total == 0: return 0.0
    ent = 0.0
    for c in counts.values():
        p = c/total
        ent -= p*math.log(p, 2)
    return ent

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--reads", required=True)
    ap.add_argument("--ref", required=True)
    ap.add_argument("--outdir", required=True)
    ap.add_argument("--umi_mode", default="from_protocol",
                    help="Placeholder: update with protocol.md-derived UMI+adapter rules.")
    # The following MUST be filled from protocol.md to avoid Incident D:
    ap.add_argument("--umi_len", type=int, default=8)
    ap.add_argument("--umi_at_5prime", action="store_true", default=True)
    ap.add_argument("--adapter", default="")  # must be set from protocol.md
    args = ap.parse_args()

    os.makedirs(args.outdir, exist_ok=True)

    ref_name, ref_seq = read_fasta_one(args.ref)
    L = len(ref_seq)

    # 1) UMI extraction (placeholder rule: UMI at 5' end of R1)
    umi_counts = Counter()
    umi_pos_base_counts = [Counter() for _ in range(args.umi_len)]
    trimmed_records = []
    total_in = 0
    kept = 0
    adapter_hits = 0

    for h, s, q in fastq_iter(args.reads):
        total_in += 1
        if args.umi_at_5prime:
            umi = s[:args.umi_len]
            s2 = s[args.umi_len:]
            q2 = q[args.umi_len:]
        else:
            # If protocol puts UMI elsewhere, implement here.
            umi = "N"*args.umi_len
            s2, q2 = s, q

        umi_counts[umi] += 1
        for i,ch in enumerate(umi[:args.umi_len]):
            umi_pos_base_counts[i][ch] += 1

        # 2) Adapter trim (must set adapter from protocol.md; if empty, no trim)
        if args.adapter:
            if args.adapter in s2:
                adapter_hits += 1
            res = simple_adapter_trim(s2, q2, args.adapter, minlen=18)
            if res is None:
                continue
            s2, q2 = res

        kept += 1
        # embed UMI in header
        h2 = h.split()[0] + f"_UMI:{umi}"
        trimmed_records.append((h2, s2, q2))

    trimmed_path = os.path.join(args.outdir, "trimmed.fastq.gz")
    write_fastq(trimmed_records, trimmed_path)

    # 3) Align to reference (minimap2 not assumed; use bowtie2 via pysam not available)
    # Here we assume an external aligner produces out/aligned.bam.
    # To keep this self-contained, we write instructions and stop if BAM missing.
    bam_path = os.path.join(args.outdir, "aligned.bam")
    if not os.path.exists(bam_path):
        instr = os.path.join(args.outdir, "ALIGN_INSTRUCTIONS.txt")
        with open(instr, "w") as f:
            f.write("Create aligned.bam by aligning out/trimmed.fastq.gz to reference.fa.\n")
            f.write("Example (bowtie2):\n")
            f.write("  bowtie2-build reference.fa refidx\n")
            f.write("  bowtie2 -x refidx -U out/trimmed.fastq.gz | samtools view -bS - > out/aligned.bam\n")
            f.write("  samtools sort -o out/aligned.sorted.bam out/aligned.bam\n")
            f.write("  samtools index out/aligned.sorted.bam\n")
        raise SystemExit(f"Missing {bam_path}. See {instr} to generate it, then re-run with aligned.sorted.bam named aligned.bam or modify script.")

    bam = pysam.AlignmentFile(bam_path, "rb")

    # 4) Raw 5' start counts
    raw_counts = [0]*(L+1)  # index by position (1..L)
    # 5) Dedup by (strand, fiveprime, UMI)
    seen = set()
    dedup_counts = [0]*(L+1)

    mapped = 0
    for r in bam.fetch(until_eof=True):
        if r.is_unmapped: 
            continue
        mapped += 1

        # extract UMI from header suffix "_UMI:XXXX"
        m = re.search(r"_UMI:([A-Z]+)", r.query_name)
        umi = m.group(1) if m else "NOUMI"

        # compute 5' position in reference coords
        if not r.is_reverse:
            fivep = r.reference_start + 1
            strand = "+"
        else:
            # reference_end is 0-based exclusive; 5' is at reference_end in 1-based
            fivep = r.reference_end
            strand = "-"

        if 1 <= fivep <= L:
            raw_counts[fivep] += 1
            key = (strand, fivep, umi)
            if key not in seen:
                seen.add(key)
                dedup_counts[fivep] += 1

    # write CSVs
    raw_csv = os.path.join(args.outdir, "counts_raw.csv")
    dedup_csv = os.path.join(args.outdir, "counts_dedup.csv")
    with open(raw_csv, "w") as f:
        f.write("position,count\n")
        for pos in range(1, L+1):
            f.write(f"{pos},{raw_counts[pos]}\n")
    with open(dedup_csv, "w") as f:
        f.write("position,count\n")
        for pos in range(1, L+1):
            f.write(f"{pos},{dedup_counts[pos]}\n")

    # plot start position hist (bar plot)
    fig, axs = plt.subplots(1, 2, figsize=(12, 3), sharex=True)
    xs = list(range(1, L+1))
    axs[0].bar(xs, [raw_counts[i] for i in xs], width=1.0)
    axs[0].set_title("5' start positions (raw)")
    axs[0].set_xlabel("transcript position (1-based)")
    axs[0].set_ylabel("count")
    axs[1].bar(xs, [dedup_counts[i] for i in xs], width=1.0)
    axs[1].set_title("5' start positions (deduplicated)")
    axs[1].set_xlabel("transcript position (1-based)")
    plt.tight_layout()
    plot_path = os.path.join(args.outdir, "startpos_hist.png")
    fig.savefig(plot_path, dpi=200)

    # UMI complexity summary
    umi_unique = len(umi_counts)
    top_umi, top_umi_n = umi_counts.most_common(1)[0] if umi_counts else ("", 0)
    entropies = [shannon_entropy(c) for c in umi_pos_base_counts]
    ent_mean = sum(entropies)/len(entropies) if entropies else 0.0

    # HTML report
    html_path = os.path.join(args.outdir, "report.html")
    with open(html_path, "w") as f:
        f.write("<html><head><meta charset='utf-8'><title>toy_gene Ribo-seq QC</title></head><body>\n")
        f.write("<h1>Single-transcript Ribo-seq pilot QC (toy_gene)</h1>\n")
        f.write("<h2>Inputs</h2>\n")
        f.write(f"<ul><li>reads: {args.reads}</li><li>reference: {args.ref} ({ref_name}, length {L})</li></ul>\n")
        f.write("<h2>Processing summary</h2>\n")
        f.write(f"<ul><li>Reads in: {total_in}</li><li>Reads kept after UMI removal / optional trim: {kept}</li>")
        if args.adapter:
            f.write(f"<li>Adapter hits (substring match): {adapter_hits}</li>")
        f.write(f"<li>Mapped reads in BAM: {mapped}</li></ul>\n")

        f.write("<h2>UMI complexity (pre-dedup)</h2>\n")
        f.write(f"<ul><li>UMI length (assumed): {args.umi_len}</li>")
        f.write(f"<li>Unique UMIs observed: {umi_unique}</li>")
        f.write(f"<li>Top UMI: {top_umi} (n={top_umi_n})</li>")
        f.write(f"<li>Mean per-position UMI entropy: {ent_mean:.3f} bits</li></ul>\n")

        f.write("<h2>Deduplication impact</h2>\n")
        f.write(f"<ul><li>Unique molecules (by strand, 5' pos, UMI): {len(seen)}</li></ul>\n")

        f.write("<h2>5' start-position distributions</h2>\n")
        f.write(f"<img src='startpos_hist.png' width='100%'/>\n")

        f.write("<h2>Interpretation checklist (fill based on observed metrics)</h2>\n")
        f.write("<ul>")
        f.write("<li>If mean UMI entropy is very low and top UMI dominates: suspect UMI extraction mis-specified (Incident D) or wrong oligo.</li>")
        f.write("<li>If starts cluster at very few positions only after dedup: possible over-collapsing or severe library bottleneck.</li>")
        f.write("<li>To assess 3-nt periodicity, CDS coordinates for toy_gene must be defined; otherwise periodicity cannot be meaningfully evaluated on this reference alone.</li>")
        f.write("</ul>\n")

        f.write("</body></html>\n")

    print("Wrote:", raw_csv, dedup_csv, plot_path, html_path)

if __name__ == "__main__":
    main()
```

### Written interpretation (what looks biologically meaningful, given what can be supported here)
- On a **single-transcript toy reference**, biological conclusions depend on whether the transcript has a defined CDS/frame annotation. With only a reference sequence and no CDS coordinates in the prompt, **true frame/periodicity QC cannot be asserted** without first defining CDS boundaries.
- The most biologically meaningful signal you can still extract is whether footprints **cluster non-uniformly** along the transcript (candidate ribosome occupancy peaks) and whether that structure **survives UMI deduplication**.

### 2–4 concrete follow-up checks / next steps (computational; tied to incidents)
1) **UMI verification (Incident D prevention):** confirm UMI location/length from `protocol.md`, then re-run the pipeline and check:
   - mean per-position UMI entropy,
   - dominance of top UMI,
   - dedup fraction.  
2) **Adapter/linker motif frequency (Incident E prevention):** scan raw reads for the exact expected linker motif from `protocol.md`; low frequency indicates library-structure failure even if alignment “works.”  
3) **Length distribution vs footprint expectation (Incident C prevention):** after correct trimming, compute trimmed read-length histogram; if many reads remain long (e.g., >40 nt), periodicity loss is expected.  
4) **Raw vs dedup start-position shape comparison:** if dedup changes the *shape* (not just scale), suspect over-collapsing/UMI mis-extraction or a severe bottleneck.

---

## Cross-incident validation & prevention plan (integrated)

### Shared upstream causes across incidents
- **Cleanup/ethanol carryover** plausibly underlies **both Incident A and B** (variable PCR efficiency, messy traces).  
- **Mismatch between wet-lab read structure and bioinformatics assumptions** plausibly underlies **Incident D** and can also distort interpretability in **C** (if trimming/extraction is wrong).  
- **Oligo specification control** is the single-point prevention for **Incident E**.

### Protocol hardening (must be implemented in `protocol.md`)
1) **Explicit “sensitive steps” with checklists**  
   - SPRI cleanup: ethanol removal, quick-spin/magnet droplet removal, drying endpoint, eluate transfer.
2) **Read-structure diagram + exact extraction/trimming rules**  
   - Put the UMI definition and adapter motifs directly in the protocol so the pipeline cannot drift.
3) **Digestion + size selection specification**  
   - Units per input, time/temp/mixing; explicit nt window and how to cut it.

### Mandatory QC gates (quantitative, stop/go)
- Cleanup inhibition gate: **A260/230 < 1.5** or qPCR replicate **Ct SD > 0.5** → stop and repeat cleanup before proceeding.  
- Ligation gate (Incident E): **no shifted ligation product** on the designated gel check → stop.  
- Footprint size gate (Incident C): if post-trim reads show substantial long-fragment mass (e.g., **>15–20% >40 nt**) → flag as non-canonical footprints and do not interpret periodicity as a Ribo-seq success criterion.  
- UMI gate (Incident D): low entropy / extreme top-UMI dominance / immediate saturation of unique UMIs → stop and verify extraction coordinates and oligo specification.

This revised plan keeps the troubleshooting grounded in the incident observations, explicitly avoids unverified claims about the provided artifacts, and supplies an executable path to generate the required single-transcript deliverables without fabricating results.