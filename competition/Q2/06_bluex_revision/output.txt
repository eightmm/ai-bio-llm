## Integrated AI Framework Objective
Design an integrated predictive framework that:
1. **Predicts cellular aging status or disease progression probability** from TERRA-related multi-omics + imaging data.
2. **Quantifies and visualizes the functional contribution of individual RNA modification types** (m6A, pseudouridine/Ψ, m5C) at both *modification-type* and *site/region* resolution.
3. **Provides mechanistic interpretability** by linking high-impact molecular features to **telomere maintenance, replication stress, DNA damage response (DDR), chromatin state, and senescence programs**, explicitly distinguishing predictive association from causal proof.

**Scope/assumption (explicit):** no dataset or results were provided; therefore, this is an **execution-ready design** plus a **mandatory pilot validation plan** (Module C) to establish feasibility before any biological claims are made.

---

# Module A: Multimodal Data Integration and Normalization

## (1) Data types and AI tools used, with scientific justification

### A.1 Data modalities (per subject/sample/timepoint)
- **Transcriptomic**
  - Bulk total RNA-seq (gene expression + repeat-aware telomeric/subtelomeric read summaries).
  - scRNA-seq (cell-state composition and senescence/DDR programs).
- **RNA modification / epitranscriptomic**
  - m6A (MeRIP-seq, miCLIP), Ψ (Ψ-seq/chemical-based maps if available), m5C (bisulfite-based or antibody-based; platform-dependent).
  - Direct RNA nanopore modification probabilities (if available) as an alternative, treated as a separate assay type due to different noise characteristics.
- **Chromatin (telomere-associated regulation)**
  - ChIP-seq for telomere-binding/maintenance factors and relevant histone marks (feature-binned in subtelomeric windows).
- **Imaging**
  - Telomere DNA-FISH + TERRA RNA-FISH; optionally super-resolution-derived morphology metrics.

### A.2 TERRA-specific challenge: repetitive mapping ambiguity (handled explicitly, not as a caveat)
Because TERRA arises from **subtelomeric** regions with highly repetitive content, **locus-resolved assignment is often unreliable**. Module A therefore produces **two parallel feature representations**:

**(i) Locus-agnostic / region-binned “telomere-proximal” features (primary for prediction)**
- Define **subtelomeric bins** (e.g., fixed-width windows adjacent to chromosome ends, at a resolution chosen to match assay and mappability; bin size is a tunable parameter).
- For each assay (RNA-seq, MeRIP/miCLIP, ChIP), compute **bin-level signals** rather than relying on unique read placement at single loci.
- Each bin’s signal is paired with an **ambiguity/QC vector**:
  - fraction of multi-mapping reads,
  - effective mappability proxy (e.g., fraction of reads with MAPQ above a threshold, platform-dependent),
  - coverage/depth metrics.

**(ii) High-confidence “uniquely anchored” features (secondary, for interpretability when justified)**
- Restrict to features supported by uniquely mappable anchors (e.g., reads spanning subtelomeric unique sequence into telomeric repeats, or peaks supported by unique flanks).
- These features are explicitly labeled **high-confidence** and carried forward for finer interpretation; they are *not assumed available everywhere*.

This two-track design prevents overclaiming locus specificity while still allowing mechanistic hypotheses where the data support it.

### A.3 Modality-specific preprocessing and normalization
- **Bulk RNA-seq**
  - Normalize counts (e.g., variance-stabilizing transform) and include batch covariates.
  - Add telomere/TERRA-relevant summaries that do not require unique mapping (e.g., bin-level subtelomeric expression; repeat-content summaries when available from the pipeline).
  - Output: expression matrix + telomere-proximal bin features + QC/ambiguity features.

- **scRNA-seq**
  - AI tool: **scVI** to denoise/integrate batches and learn cell embeddings.
  - Aggregate to sample/timepoint features: cell-type proportions; senescence/DDR program scores; stress-state abundances.
  - Output: sample-level scRNA feature vector + uncertainty (if available from the model).

- **RNA modifications (m6A/Ψ/m5C)**
  - Treat each modification type as a **separate block** with its own preprocessing and reliability metrics.
  - Normalize with assay-appropriate controls (e.g., IP/Input-type normalization when available) and include depth/coverage.
  - Compute **bin-level modification burden** (primary) plus optional high-confidence site/peak features (secondary), each with:
    - signal intensity/probability,
    - coverage,
    - replicate concordance (when replicates exist),
    - ambiguity/mappability proxies.
  - Output: aligned feature blocks `{m6A_block, Psi_block, m5C_block}` + reliability/QC vectors.

- **ChIP-seq**
  - Produce subtelomeric bin signals and peak features (where confident).
  - Include QC (e.g., FRiP-like metrics) and batch covariates.
  - Output: chromatin feature matrix + QC.

- **Imaging**
  - AI tool for segmentation: **Cellpose** *with domain calibration* (see validation below).
  - Produce engineered telomere/TERRA features:
    - telomere foci count/intensity distributions,
    - TERRA foci count/intensity,
    - telomere–TERRA colocalization/proximity metrics,
    - morphology/spatial dispersion features.
  - Optional learned embeddings: a vision encoder **trained or fine-tuned on in-domain images** (self-supervised pretraining on the same microscopy domain when labels are limited).
  - Output: imaging feature vector + per-image QC (focus quality, segmentation confidence proxies).

### A.4 Cross-modal integration tool (designed for scalability + missing modalities)
**Primary integrator:** a **modular multimodal latent-variable model (multimodal VAE)** with:
- **separate encoders per modality** producing low-dimensional modality latents (e.g., 32-d each),
- a **shared latent** `z_shared` (e.g., 16–32-d) learned via a product-/mixture-of-experts aggregation,
- **explicit modality masks** enabling training/inference with missing modalities,
- likelihoods matched to data type (counts vs continuous).

**Training stability safeguards (explicit)**
- KL warm-up/annealing schedule, gradient clipping, early stopping on held-out reconstruction + downstream predictive loss proxy, and modality-balanced minibatching.
- Dimensionality control: tokenize/bucket features into fixed maximum tokens per block (details in Module B).

### A.5 Module A outputs
1. `z_shared`: unified sample-level latent representation.
2. Optional modality-specific latents `z_m6A`, `z_Psi`, `z_m5C`, `z_expr`, `z_chip`, `z_img`.
3. Preserved feature blocks `{m6A_block, Psi_block, m5C_block}` (region-binned primary + optional high-confidence peaks).
4. A **QC/ambiguity table** per sample and per block (coverage, multi-mapping proxies, replicate concordance).

---

## (2) Alternative design choices and why they were not selected
- **MOFA+ (linear factor model) as the primary integrator**
  - Not selected as primary because imaging embeddings and modification–expression interactions are often nonlinear and heteroscedastic; however, MOFA+ is retained as a **required baseline** in Module C to verify whether nonlinearity provides measurable benefit.
- **Simple concatenation + ComBat/Harmony + PCA**
  - Not selected due to missing-modality fragility and weaker uncertainty handling; also tends to blur modification-type separation required for attribution.
- **Full end-to-end “single giant model” without modality-specific QC/ambiguity channels**
  - Not selected because repeat-derived ambiguity is a core TERRA constraint; QC/ambiguity must be explicit inputs to prevent confounding.

---

## (3) How Module A outputs feed into the next stage
- `z_shared` is the compact representation for Module B prediction.
- The **separate modification blocks** (m6A/Ψ/m5C) plus their **reliability/QC features** are passed to Module B to enable:
  - modification-type-specific learning,
  - confounding control for coverage/ambiguity,
  - interpretable attribution at the correct granularity.
- Imaging and ChIP features (and QC) are passed as additional tokens/blocks.

---

# Module B: Predictive Model Design

## (1) Data types and AI tools used, with scientific justification

### B.1 Targets (task-dependent)
- **Aging**: binary or ordinal/multiclass labels.
- **Disease progression**:
  - classification (progressed vs not),
  - and/or **time-to-event** (survival with censoring),
  - and/or longitudinal risk forecasting across multiple timepoints.

### B.2 Primary predictor: Multimodal Transformer with reliability-aware tokens
**Inputs (tokenized blocks)**
- Context token: `z_shared`.
- Block tokens:
  - m6A tokens, Ψ tokens, m5C tokens (region bins and/or high-confidence peaks),
  - expression tokens (selected genes/signatures + scRNA-derived state scores),
  - ChIP tokens (subtelomeric bins/peaks),
  - imaging tokens (engineered features + optional image embedding).

**Reliability/ambiguity conditioning (critical for TERRA)**
- Each token carries side-channel features (or embedding augmentations) including:
  - coverage/depth,
  - multi-mapping proxy / ambiguity score,
  - replicate concordance (if available),
  - batch indicators.
This allows the model to learn *when not to trust a signal*, reducing spurious importance driven by assay artifacts.

**Model configuration (reproducibility defaults; tunable)**
- 2–4 Transformer encoder layers, 4–8 attention heads, embedding dim 128–256.
- Modality dropout during training: randomly mask entire blocks with probability 0.1–0.3 to improve robustness to missing modalities.
- Token caps to ensure scalability (example policy): per modification block, keep a fixed number of region bins and/or top-variable peaks; the exact cap is set before training and kept constant across samples to avoid feature-count confounding.

### B.3 Longitudinal / time-to-event handling (explicit)
If repeated measures exist:
- Use a **visit-level sequence model**:
  - encode each timepoint as a token set → pooled embedding,
  - apply a temporal module (Transformer/RNN) with **time-delta embeddings** to handle irregular intervals.
- Survival head options:
  - discrete-time hazard model (handles varying intervals naturally),
  - or Cox-type head if assumptions are acceptable.
- Address informative timing risk by including observation-time features (e.g., time since baseline, visit density indicators) as covariates; evaluation uses time-aware splits (Module C).

### B.4 Outputs
- `p(aging)` and/or `p(progression)`; optionally survival risk/hazard.
- Stored explanation hooks: gradients, integrated-gradient baselines, token embeddings, and masked-modality outputs.

---

## (2) Alternative design choices and why they were not selected
- **XGBoost/Random Forest on concatenated features**
  - Not selected as primary because token-level interactions across assays (modifications × chromatin × imaging) are central, and missing-modality handling/QC conditioning is less natural; retained as a baseline in Module C.
- **Graph Neural Network over locus–gene–pathway graphs**
  - Not selected as primary because reliable locus assignment for TERRA-linked signals is often ambiguous; a GNN becomes brittle if the underlying graph is misspecified. It can be a later extension once high-confidence anchors are established.
- **Mixture-of-Experts**
  - Not selected initially due to added complexity and reproducibility burden; can be considered if strong heterogeneity across disease subtypes is demonstrated during validation.

---

## (3) How Module B outputs feed into the next stage
- Predictions feed Module C for discrimination, calibration, robustness, and longitudinal validity checks.
- Stored token-level signals enable:
  - modification-type and region-level attribution,
  - reliability-aware interpretation,
  - controlled contribution analyses that account for coverage and token counts.

---

# Module C: Model Interpretation and Evaluation

## (1) Data types and AI tools used, with scientific justification

### C.1 Feasibility and empirical validation plan (required before claims)
Because the framework is otherwise theoretical, the following validation steps are mandatory outputs of Module C:
- **Baselines:** compare against MOFA+→logistic/Cox, and concatenation→XGBoost (same splits).
- **Ablation-by-modality stress tests:** evaluate performance when entire modalities are missing at inference (imaging-only missing, ChIP-only missing, each modification type missing).
- **Repeat-ambiguity sensitivity:** stratify evaluation by high vs low ambiguity/QC strata (e.g., low vs high multi-mapping proxy) to confirm predictions are not driven solely by mapping artifacts.
- **Calibration and uncertainty:** reliability curves/ECE and confidence intervals via bootstrap.

No numeric results are asserted here; this module specifies how results must be produced to establish feasibility.

### C.2 Quantifying contribution of each RNA modification type (m6A vs Ψ vs m5C) without confounding
Block-wise ablation alone is confounded by differences in token count and measurement quality. Therefore, contribution is quantified using a **three-part controlled strategy**:

1. **Reliability-matched ablation (type-level, model-agnostic)**
   - When masking a modification type, replace its tokens with:
     - a fixed “missing” embedding **and**
     - keep its coverage/QC tokens present (so the model can’t trivially detect removal as a distribution shift).
   - Additionally, enforce **token-count matching** across types (fixed cap per block) so Δ-performance is not dominated by dimensionality.

2. **Conditional permutation importance (type-level, confound-aware)**
   - Within each modification type, permute modification signals **within strata of coverage/ambiguity** (e.g., bins of depth and multi-mapping proxy) to preserve measurement-quality distributions.
   - Measure Δ-performance; this better isolates biological signal from assay quality.

3. **Group attributions (site/bin-level, model-aware)**
   - Compute **Integrated Gradients** (or DeepSHAP if implemented consistently) at token level.
   - Aggregate attributions:
     - per modification type (global),
     - per subtelomeric bin (regional),
     - per sample (individualized explanations),
   - and report alongside token reliability to say “high attribution under high confidence” vs “high attribution under low confidence.”

### C.3 Visualization deliverables (explicit requirement)
- **Global modification-type contribution**
  - Bar plot: controlled Δ-metric (e.g., ΔAUROC/ΔC-index) from reliability-matched ablation and conditional permutation for m6A/Ψ/m5C, with bootstrap CIs.
- **Region-level “telomere-proximal track”**
  - x-axis: subtelomeric bins; y-axis: aggregated absolute attribution; color: modification type; overlay ambiguity as transparency (so repetitive uncertainty is visible).
- **Per-sample explanation card**
  - Predicted risk + calibration-adjusted probability.
  - Top contributing bins/peaks per modification type with attribution sign/magnitude and confidence (coverage/ambiguity).
  - Key non-modification drivers (e.g., telomere morphology features) to contextualize cross-modal interplay.

### C.4 Mechanistic interpretability linked to biological pathways (strengthened and appropriately qualified)
To meet the mechanistic requirement without overclaiming causality, the framework provides **two complementary interpretability layers**:

1. **Pathway-concept layer (more mechanistic than post-hoc GSEA alone)**
   - Derive pathway/activity scores from expression and/or chromatin features (e.g., predefined telomere/DDR/senescence programs available in the dataset’s annotation plan).
   - Use a **concept-bottleneck style predictor** (or a constrained auxiliary head) where:
     - the model predicts pathway activities from upstream features (including modification blocks),
     - and then predicts aging/progression from these pathway activities.
   - Output: which pathways most mediate the predictive signal **within the model** (interpretable but still associative).

2. **Post-hoc enrichment (kept, but explicitly framed as associative)**
   - Map high-attribution bins/peaks to nearby genes **only when anchors are high-confidence**; otherwise report enrichment at the *regional/bin* level without claiming gene-level specificity.
   - Run enrichment to summarize biological themes, reported as **hypothesis-generating** links rather than causal mechanisms.

### C.5 Imaging integration: domain-specific validation (explicit)
- Validate segmentation/feature extraction by:
  - QC gating (blur/focus, stain intensity, nucleus segmentation confidence proxies),
  - reproducibility across technical replicates/batches (where available),
  - sanity checks on distributions (e.g., telomere foci count/intensity stability across control groups).
- If learned embeddings are used:
  - require in-domain pretraining/fine-tuning and evaluate whether embeddings correlate with engineered telomere metrics; if not, embeddings are excluded to avoid unvalidated black-box signals.

### C.6 Evaluation protocol (required for scientific validity)
- **Splits**
  - Subject-level splits to prevent leakage.
  - If longitudinal: time-aware evaluation (e.g., train on earlier windows, test on later), while also reporting performance across visit-time strata to detect timing bias.
- **Metrics**
  - Classification: AUROC, AUPRC, balanced accuracy; calibration (ECE/reliability curves).
  - Survival: C-index, time-dependent calibration (as supported by implementation), and Brier-type scores where applicable.
- **Robustness**
  - Missing-modality tests, batch/site stratification, ambiguity-stratified performance.
- **Reproducibility minimums (reported with results)**
  - token caps per block, modality dropout rate, optimizer and learning rate schedule, early stopping criteria, attribution method and baseline, and the thresholding rule for “top features” (e.g., top-k per sample or percentile cutoff—chosen once and fixed).

---

## (2) Alternative design choices and why they were not selected
- **Attention weights as explanations**
  - Not used as primary because attention ≠ importance; allowed only as a supplementary diagnostic.
- **LIME/kernel SHAP as sole interpretability**
  - Not primary due to instability in high-dimensional correlated token spaces; can be used on reduced feature sets as a sensitivity check.
- **Gene-centric mapping without ambiguity handling**
  - Not selected because TERRA/subtelomeric ambiguity can make gene assignment unreliable; the framework prioritizes bin-level mechanistic summaries unless uniquely anchored.

---

## (3) How Module C outputs feed into the next stage (iterative refinement)
- If a modification type shows high controlled contribution but low confidence (driven by low-coverage/ambiguous tokens), refine Module A filters and tokenization to prioritize high-confidence bins/anchors.
- If imaging embeddings fail domain validation, fall back to engineered telomere/TERRA features only.
- If MOFA+/simpler baselines match performance, simplify Module A/B to improve interpretability and reproducibility.
- High-confidence bins/peaks and pathway-concepts become a prioritized mechanistic hypothesis list, explicitly labeled as **predictive associations** pending experimental validation outside this computational scope.

---

## End-to-end Flow Summary (A → B → C)
1. **Module A** constructs **TERRA-appropriate, ambiguity-aware** multi-omics and imaging features, preserves separate **m6A/Ψ/m5C** blocks, and integrates modalities into `z_shared` using a stability-controlled multimodal latent model.
2. **Module B** predicts aging/progression using a **reliability-aware multimodal Transformer** (and time-aware modeling if longitudinal), outputting calibrated probabilities/risk.
3. **Module C** provides **empirical feasibility validation**, controlled quantification of modification-type contributions (avoiding coverage/dimensionality confounding), explicit visualizations, and mechanistic interpretability via pathway-concepts plus carefully qualified enrichment, while reporting robustness to missing modalities and repeat-mapping ambiguity.